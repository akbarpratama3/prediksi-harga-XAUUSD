# -*- coding: utf-8 -*-
"""model2_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eIyHirrlny1PibZmjw36hM7CWVOyumO4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive/')

df = pd.read_csv ('/content/drive/MyDrive/skripsi/predik/campus eksp/XAU_USD Historical Data (4).csv')

#melihat info data yang sudah diubah tipedata
df.info()

#menghapus fitur volume
df = df.drop(columns=['Vol.'])

#mengubah tepidata menjadi datatime
df['Date'] = pd.to_datetime(df['Date'])

#mengubah tipedata menjadi float
df['Price'] = df['Price'].str.replace(',', '').astype(float)

#mengubah tipedata menjadi float
df['Open'] = df['Open'].str.replace(',', '').astype(float)

#mengubah tipedata menjadi float
df['High'] = df['High'].str.replace(',', '').astype(float)

#mengubah tipedata menjadi float
df['Low'] = df['Low'].str.replace(',', '').astype(float)

# Menghapus simbol '%' dan mengubah tipe data menjadi float
df['Change %'] = df['Change %'].str.replace('%', '').str.replace(',', '').astype(float)

df.info()

# Menghitung matriks korelasi
correlation_matrix = df.drop(columns=["Date"]).corr()

# Menampilkan matriks korelasi
plt.figure(figsize=(7, 5))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

# Menentukan fitur target yang potensial
# Kriteria: Fitur yang memiliki korelasi tinggi dengan sebagian besar fitur lainnya
correlation_sum = correlation_matrix.sum(axis=0) - 1  # Menghitung jumlah korelasi (mengabaikan dirinya sendiri)
target_candidate = correlation_sum.idxmax()  # Fitur dengan total korelasi tertinggi
print("Fitur target yang paling potensial berdasarkan hubungan dengan fitur lain adalah:", target_candidate)
# Menampilkan skor korelasi untuk setiap fitur
print("\nTotal skor korelasi setiap fitur:")
print(correlation_sum)

#mengambil fitur Date sebagai indeks dan fitur Price sebagai target
df = df [['Date', 'Price']].set_index('Date')

#melihat fitur yang diambil
print(df)

df.describe()

#menampilkan visualisasi price XAU/USD
plt.style.use('default')
plt.figure(figsize=(16,5))
plt.title('Harga XAU/USD 5 tahun terakhir')
plt.plot( df['Price'], linewidth=1.2, color='#227E19')
plt.xlabel('Tanggal')
plt.ylabel('dollar(usd)')
plt.xticks(rotation=45)
plt.grid(True,linewidth=0.18, axis='y')
plt.show()

sc = MinMaxScaler(feature_range=(0, 1))  #Normalisasi untuk mengubah nilai dalam rentang antara 0 dan 1
data = df['Price'].values.reshape(-1, 1) #Mengambil data dari kolom Price dan Mengubah array 1 dimensi menjadi array 2 dimensi (dengan bentuk [n_samples, 1])
scaled_data = sc.fit_transform(data)     # Melakukan normalisasi pada data

# Mengubah array hasil normalisasi (scaled_data) menjadi sebuah DataFrame dan Memberikan nama kolom baru, yaitu "Normalisasi (Price)", untuk hasil normalisasi.
scaled_df = pd.DataFrame(scaled_data, index=df.index, columns=['Normalisasi (Price)'])
print(scaled_df)

training_data_len = int(len(data) * 0.8)         #Mengambil 80% dari total data untuk digunakan sebagai data pelatihan.
train_data = scaled_data[:training_data_len, :] #Membagi dataset yang telah dinormalisasi sebelumnya (dengan MinMaxScaler)
x_train = []#Akan menyimpan input untuk model LSTM
y_train = []#Akan menyimpan target output (label) yang diprediksi oleh model

#Menggunkan loop untuk embentuk dataset dengan sliding window dan Mengambil 60 data sebelumnya dari data pelatihan
#Data ini dimasukkan ke dalam x_train sebagai satu set input dan y_train sebagai target output
for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])

x_train, y_train = np.array(x_train), np.array(y_train)#Mengubah data x_train dan y_train ke array NumPy untuk digunakan dalam model
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))#Mengubah bentuk data input (x_train) menjadi format 3D [samples, time_steps, features], yang diperlukan untuk melatih model LSTM.

from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_percentage_error
import tensorflow as tf
from tensorflow.keras.models import Sequential

# Pembangunan Model LSTM
model = Sequential()

model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(Dropout(0.2))

model.add(LSTM(units=50))
model.add(Dropout(0.2))

model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')

history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2, shuffle=False)

# Plot Learning Curve
plt.figure(figsize=(13, 6))
plt.plot(history.history['loss'], label='Training Loss', color='#227E19')
plt.plot(history.history['val_loss'], label='Validation Loss', color='#EBAF25')
plt.title('Learning Curve', fontsize=20)
plt.xlabel('Epochs', fontsize=16)
plt.ylabel('Loss', fontsize=16)
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

test_data = scaled_data[training_data_len - 60:, :] #sebagai input prediksi data uji dapat dimulai dengan konteks historis 60 data terakhir dari scaled_data
x_test = [] #data input untuk prediksi
y_test = data[training_data_len:, :] #Target data aktual digunakan untuk evaluasi hasil prediksi.
# Membuat data input uji dengan sliding window
for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])

x_test = np.array(x_test) #Mengubah ke Array NumPy agar dapat digunakan dalam model
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1)) #Mengubah bentuk x_test menjadi [samples, time steps, features]

predictions = model.predict(x_test) #Menggunakan model LSTM yang sudah dilatih untuk memprediksi data uji
predictions = sc.inverse_transform(predictions) #Mengubah prediksi yang sebelumnya dinormalisasi (skala 0-1) kembali ke skala aslinya (harga sebenarnya)/

valid = pd.DataFrame() #Membuat DataFrame kosong untuk menyimpan data perbandingan antara harga aktual dan hasil prediksi.
valid['Real Price'] = df['Price'][training_data_len:].reset_index(drop=True) #Mengambil kolom harga aktual ("Price") dari DataFrame asli (df).
valid['Predictions'] = predictions #Hasil prediksi dari model LSTM yang sudah diubah ke skala harga asli dan menyimpan nilai prediksi yang akan dibandingkan dengan harga aktual
print(valid)

#visualisasi perbandingan harga aktual dan predi
valid = pd.DataFrame()
valid['Real Price'] = df['Price'][training_data_len:]
valid['Predictions'] = predictions
plt.figure(figsize=(16, 7))
plt.title('Perbandingan Harga Aktual dan Prediksi', fontsize=20)
plt.xlabel('Tanggal', fontsize=17)
plt.ylabel('Harga Penutupan (USD)', fontsize=17)
plt.plot(valid['Real Price'], label='Real Price',color='#252F75')
plt.plot(valid['Predictions'], label='Predictions',color='#EA2641', )
plt.legend(fontsize=14)
plt.show()

#visualisasi data train, valid, dan predic
train = df[:training_data_len]
valid = df[training_data_len:]
valid['Predictions'] = predictions
plt.figure(figsize=(16, 8))
plt.title('Model LSTM untuk Prediksi XAU/USD', fontsize=20)
plt.xlabel('Tanggal', fontsize=17)
plt.ylabel('Harga Penutupan USD', fontsize=17)
plt.plot(train['Price'], label='Train', color='#227E19', )
plt.plot(valid['Price'], label='Valid', color='#EBAF25', )
plt.plot(valid['Predictions'], label='Predictions',color='#EA2641', )
plt.legend(loc='lower right', fontsize=14)
plt.grid(True)
plt.show()

#rmse evaluasi RMSE mengukur seberapa besar kesalahan model antara data aktual dan predic
rmse = np.sqrt(mean_squared_error(valid['Price'], valid['Predictions']))
print('Root Mean Squared Error:', rmse)

# R-squared mengukur sejauh mana model dapat menangkap pola dalam data
r2 = r2_score(valid['Price'],valid['Predictions'])
print('R-squared:', r2)

# MAPE mengukur kesalahan rata-rata dalam bentuk persentase
mape = mean_absolute_percentage_error(valid['Price'], valid['Predictions'])
print('Mean Absolute Percentage Error:', mape * 100)

import pickle

# Simpan model dan objek lainnya
model.save('model_lstm.h5')

with open('scaler.pkl', 'wb') as f:
    pickle.dump(sc, f)

df.to_pickle('dataframe.pkl')

import pickle
from tensorflow.keras.models import load_model
# Muat kembali model LSTM
model = load_model('/content/model_lstm.h5')

# Muat kembali scaler
with open('scaler.pkl', 'rb') as f:
    sc = pickle.load(f)

# Muat kembali DataFrame
df = pd.read_pickle('/content/dataframe.pkl')

from datetime import datetime, timedelta
import matplotlib.pyplot as plt
# Muat kembali DataFrame
df = pd.read_pickle('/content/dataframe.pkl')

# Fungsi untuk melakukan prediksi dan menampilkan hasil
def predict_range_and_plot(start_date, end_date):
    # Pastikan start_date dan end_date dalam format datetime
    start_date = datetime.strptime(start_date, "%Y-%m-%d")
    end_date = datetime.strptime(end_date, "%Y-%m-%d")

    # Validasi input tanggal
    if end_date <= start_date:
        print("Tanggal akhir harus lebih besar dari tanggal awal.")
        return None

    # Hitung jumlah hari yang akan diprediksi
    total_days = (end_date - start_date).days + 1

    # Ambil data terbaru untuk memulai prediksi (60 hari terakhir)
    recent_data = df['Price'][-60:].values.reshape(-1, 1)
    recent_scaled = sc.transform(recent_data)

    # Reshape untuk input ke model LSTM
    x_input = np.reshape(recent_scaled, (1, recent_scaled.shape[0], 1))

    # Inisialisasi array untuk menyimpan prediksi
    predictions = []

    # Prediksi untuk setiap hari dalam rentang tanggal
    for _ in range(total_days):
        # Prediksi hari berikutnya
        next_prediction = model.predict(x_input)

        # Inverse transform untuk mendapatkan nilai asli
        next_prediction_scaled = sc.inverse_transform(next_prediction)

        # Tambahkan prediksi ke dalam list
        predictions.append(next_prediction_scaled[0][0])

        # Update x_input dengan prediksi terbaru untuk prediksi berikutnya
        x_input = np.append(x_input[:, 1:, :], [[next_prediction[0]]], axis=1)

    # Buat DataFrame untuk prediksi dengan tanggal
    prediction_dates = pd.date_range(start=start_date, end=end_date)
    predicted_df = pd.DataFrame({
        'Tanggal': prediction_dates,
        'Prediksi Harga Penutupan (USD)': predictions
    })

    # Plot grafik
    plt.figure(figsize=(12, 6))
    plt.plot(df.index[-100:], df['Price'][-100:], label='Harga Historis', color='#227E19')  # Menampilkan data historis 100 hari terakhir
    plt.plot(predicted_df['Tanggal'], predicted_df['Prediksi Harga Penutupan (USD)'], label='Prediksi Harga', color='#EA2641', linestyle='--')
    plt.title('Prediksi Harga XAU/USD', fontsize=16)
    plt.xlabel('Tanggal', fontsize=12)
    plt.ylabel('Harga Penutupan (USD)', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.legend(fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Tampilkan tabel prediksi
    print(predicted_df)

# Input tanggal awal dan akhir
start_date = input("Masukkan tanggal awal (format: YYYY-MM-DD): ")
end_date = input("Masukkan tanggal akhir (format: YYYY-MM-DD): ")

# Melakukan prediksi dan menampilkan hasil
predict_range_and_plot(start_date, end_date)

